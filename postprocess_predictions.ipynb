{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a14a05-dcd2-45c5-840f-a36e6a1755af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T02:40:04.053215Z",
     "iopub.status.busy": "2025-10-08T02:40:04.052836Z",
     "iopub.status.idle": "2025-10-08T02:40:08.518200Z",
     "shell.execute_reply": "2025-10-08T02:40:08.516930Z",
     "shell.execute_reply.started": "2025-10-08T02:40:04.053188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file: /home/sagemaker-user/RCT NEW/rct_model_project/model/xgb.json\n",
      "Test file : /home/sagemaker-user/RCT NEW/rct_model_project/rct_train/test.csv\n",
      "Loading test.csv ...\n",
      "\n",
      "=== Fleet-average time per SOC band (corrected) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_170/629372057.py:172: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_total = float(df_pred.groupby(sid_col).apply(lambda g: total_time_between(g, 20, 80)).mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soc_band</th>\n",
       "      <th>avg_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20–25%</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25–30%</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30–35%</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35–40%</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40–45%</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45–50%</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50–55%</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55–60%</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60–65%</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65–70%</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70–75%</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75–80%</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80–80%</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   soc_band  avg_minutes\n",
       "0    20–25%         0.17\n",
       "1    25–30%         0.37\n",
       "2    30–35%         0.31\n",
       "3    35–40%         0.40\n",
       "4    40–45%         0.68\n",
       "5    45–50%         0.61\n",
       "6    50–55%         0.84\n",
       "7    55–60%         0.62\n",
       "8    60–65%         0.79\n",
       "9    65–70%         0.56\n",
       "10   70–75%         0.44\n",
       "11   75–80%         0.30\n",
       "12   80–80%         0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated average total charging time 20→80% SOC: 4.64 minutes\n",
      "\n",
      "✅ Done: realistic predictions from your existing model.\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Post-processing: realistic SOC-band RCT (no retrain / no redeploy)\n",
    "# ===============================================================\n",
    "\n",
    "import os, numpy as np, pandas as pd, xgboost as xgb\n",
    "\n",
    "# ---------- PATHS ----------\n",
    "BASE_DIR  = \"/home/sagemaker-user/RCT NEW/rct_model_project\"\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"model\")\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"rct_train\")\n",
    "print(\"Model file:\", os.path.join(MODEL_DIR, \"xgb.json\"))\n",
    "print(\"Test file :\", os.path.join(TRAIN_DIR, \"test.csv\"))\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def load_feature_list(model_dir=MODEL_DIR):\n",
    "    with open(os.path.join(model_dir, \"feature_list.txt\"), \"r\") as f:\n",
    "        return [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "def order_features(df, model_dir=MODEL_DIR):\n",
    "    feats = load_feature_list(model_dir)\n",
    "    return pd.DataFrame({c: df.get(c, np.nan) for c in feats})[feats]\n",
    "\n",
    "def smooth_series(s, win=3):\n",
    "    return s.rolling(win, center=True, min_periods=1).median()\n",
    "\n",
    "def interp_at(x, y, xq):\n",
    "    x = np.asarray(x); y = np.asarray(y)\n",
    "    return float(np.interp(xq, x, y, left=y[0], right=y[-1]))\n",
    "\n",
    "def bucket_label(i_abs, edges=(0,1,5,10,20,40,80,200,1000)):\n",
    "    if i_abs is None or np.isnan(i_abs): return None\n",
    "    for a,b in zip(edges[:-1], edges[1:]):\n",
    "        if a <= i_abs < b: return f\"{a}–{b} A\"\n",
    "    return f\"{edges[-2]}+ A\"\n",
    "\n",
    "# ---------- load data ----------\n",
    "print(\"Loading test.csv ...\")\n",
    "df = pd.read_csv(os.path.join(TRAIN_DIR, \"test.csv\"))\n",
    "\n",
    "# Keep columns we need for post-processing (even if they are features)\n",
    "must_keep = [c for c in [\n",
    "    \"soc\", \"elapsed_min\", \"timestamp_local\", \"vehicle\",\n",
    "    \"session_key\", \"session_id\",\n",
    "    \"current\", \"current_master\", \"current_slave\",\n",
    "    \"voltage\", \"voltage_master\", \"voltage_slave\"\n",
    "] if c in df.columns]\n",
    "\n",
    "# Build X exactly as the model expects\n",
    "X = order_features(df)\n",
    "\n",
    "# ---------- load model ----------\n",
    "bst = xgb.Booster()\n",
    "bst.load_model(os.path.join(MODEL_DIR, \"xgb.json\"))\n",
    "\n",
    "# ---------- robust predict (align feature names) ----------\n",
    "def make_dmatrix_aligned(X, bst):\n",
    "    if bst.feature_names is not None:\n",
    "        model_feats = list(bst.feature_names)\n",
    "        # Case: model stored generic f0,f1,... → pass numpy (no names)\n",
    "        if all(str(n).startswith(\"f\") and str(n)[1:].isdigit() for n in model_feats):\n",
    "            return xgb.DMatrix(X.to_numpy(copy=True))\n",
    "        # Case: model stored real names → reorder to match\n",
    "        missing = [c for c in model_feats if c not in X.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Data missing features expected by model: {missing[:20]} ...\")\n",
    "        X2 = X[model_feats]\n",
    "        return xgb.DMatrix(X2, feature_names=model_feats)\n",
    "    # Model has no names → pass numpy\n",
    "    return xgb.DMatrix(X.to_numpy(copy=True))\n",
    "\n",
    "try:\n",
    "    dmat = make_dmatrix_aligned(X, bst)\n",
    "    preds = bst.predict(dmat)\n",
    "except Exception as e:\n",
    "    print(\"Primary alignment failed:\", e, \"\\nRetrying with name-less inputs ...\")\n",
    "    bst.feature_names = None\n",
    "    dmat = xgb.DMatrix(X.to_numpy(copy=True))\n",
    "    preds = bst.predict(dmat)\n",
    "\n",
    "# Attach predictions + the columns we must keep\n",
    "df_pred = df[must_keep].copy()\n",
    "df_pred[\"predicted_rct\"] = preds\n",
    "\n",
    "# Sanity: ensure SOC exists\n",
    "assert \"soc\" in df_pred.columns, \"SOC not found in dataframe; cannot compute band times.\"\n",
    "\n",
    "# ---------- build sessions if missing ----------\n",
    "def build_sessions_if_missing(dfin):\n",
    "    if (\"session_key\" in dfin.columns) or (\"session_id\" in dfin.columns):\n",
    "        return dfin\n",
    "    s = dfin.copy()\n",
    "    # Sorting preference: vehicle > elapsed_min > timestamp > soc\n",
    "    sort_cols = []\n",
    "    if \"vehicle\" in s.columns:          sort_cols.append(\"vehicle\")\n",
    "    if \"elapsed_min\" in s.columns:      sort_cols.append(\"elapsed_min\")\n",
    "    elif \"timestamp_local\" in s.columns:sort_cols.append(\"timestamp_local\")\n",
    "    else:                               sort_cols.append(\"soc\")\n",
    "    s = s.sort_values(sort_cols).reset_index(drop=True)\n",
    "\n",
    "    d_soc = s[\"soc\"].diff().fillna(0)\n",
    "    long_gap = pd.Series(False, index=s.index)\n",
    "    time_back = pd.Series(False, index=s.index)\n",
    "    if \"elapsed_min\" in s.columns:\n",
    "        t_diff   = s[\"elapsed_min\"].diff().fillna(0)\n",
    "        long_gap = t_diff > 60\n",
    "        time_back= t_diff < 0\n",
    "\n",
    "    new_session = (d_soc < -1.0) | long_gap | time_back\n",
    "    s[\"session_key\"] = new_session.cumsum().astype(int)\n",
    "    return s\n",
    "\n",
    "df_pred = build_sessions_if_missing(df_pred)\n",
    "\n",
    "# ---------- compute minutes per SOC band (correct math) ----------\n",
    "soc_bins = list(range(20, 85, 5)) + [80]        # 20,25,...,80\n",
    "labels   = [f\"{soc_bins[i]}–{soc_bins[i+1]}%\" for i in range(len(soc_bins)-1)]\n",
    "\n",
    "# choose current columns if present (for bucket labels only)\n",
    "curr_cols   = [c for c in df_pred.columns if \"current\" in c.lower()]\n",
    "i_master_col = [c for c in curr_cols if \"slave\" not in c][:1]\n",
    "i_master_col = i_master_col[0] if i_master_col else (curr_cols[0] if curr_cols else None)\n",
    "i_slave_col  = [c for c in curr_cols if \"slave\" in c][:1]\n",
    "i_slave_col  = i_slave_col[0] if i_slave_col else None\n",
    "\n",
    "sid_col = \"session_key\" if \"session_key\" in df_pred.columns else (\"session_id\" if \"session_id\" in df_pred.columns else None)\n",
    "assert sid_col is not None, \"Could not create session groups; need 'soc' and some notion of order (elapsed_min/timestamp).\"\n",
    "\n",
    "def summarize_session(sess_df):\n",
    "    s = sess_df.sort_values(\"soc\").copy()\n",
    "    s[\"predicted_rct_smooth\"] = smooth_series(s[\"predicted_rct\"])\n",
    "\n",
    "    def rct_at(p): return interp_at(s[\"soc\"], s[\"predicted_rct_smooth\"], p)\n",
    "\n",
    "    rows = []\n",
    "    for lo, hi, lab in zip(soc_bins[:-1], soc_bins[1:], labels):\n",
    "        rct_lo = rct_at(lo)\n",
    "        rct_hi = rct_at(hi)\n",
    "        minutes_in_band = max(0.0, rct_lo - rct_hi)   # <-- key fix\n",
    "\n",
    "        band = s[(s[\"soc\"] >= lo) & (s[\"soc\"] < hi)]\n",
    "        i_med_master = float(np.median(np.abs(band[i_master_col]))) if (i_master_col and not band.empty) else np.nan\n",
    "        i_med_slave  = float(np.median(np.abs(band[i_slave_col ]))) if (i_slave_col  and not band.empty) else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"soc_band\": lab,\n",
    "            \"minutes_in_band\": minutes_in_band,\n",
    "            \"median_master_A\": i_med_master,\n",
    "            \"median_slave_A\":  i_med_slave,\n",
    "            \"master_current_bucket\": bucket_label(i_med_master),\n",
    "            \"slave_current_bucket\":  bucket_label(i_med_slave),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "tables = []\n",
    "for sid, g in df_pred.groupby(sid_col):\n",
    "    t = summarize_session(g)\n",
    "    t[sid_col] = sid\n",
    "    tables.append(t)\n",
    "\n",
    "result = pd.concat(tables, ignore_index=True)\n",
    "\n",
    "fleet = (result.groupby(\"soc_band\")[\"minutes_in_band\"]\n",
    "         .mean().reset_index().rename(columns={\"minutes_in_band\":\"avg_minutes\"}))\n",
    "\n",
    "# ---------- total time 20→80% ----------\n",
    "def total_time_between(sess_df, a, b):\n",
    "    s = sess_df.sort_values(\"soc\").copy()\n",
    "    s[\"predicted_rct_smooth\"] = smooth_series(s[\"predicted_rct\"])\n",
    "    def rct_at(p): return interp_at(s[\"soc\"], s[\"predicted_rct_smooth\"], p)\n",
    "    return max(0.0, rct_at(a) - rct_at(b))\n",
    "\n",
    "avg_total = float(df_pred.groupby(sid_col).apply(lambda g: total_time_between(g, 20, 80)).mean())\n",
    "\n",
    "# ---------- outputs ----------\n",
    "print(\"\\n=== Fleet-average time per SOC band (corrected) ===\")\n",
    "display(fleet.assign(avg_minutes=lambda d: d[\"avg_minutes\"].round(2)))\n",
    "\n",
    "print(f\"\\nEstimated average total charging time 20→80% SOC: {avg_total:.2f} minutes\")\n",
    "print(\"\\n✅ Done: realistic predictions from your existing model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0c891a-cb5b-4f1f-a466-75ab427142b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T03:17:54.743611Z",
     "iopub.status.busy": "2025-10-08T03:17:54.743021Z",
     "iopub.status.idle": "2025-10-08T03:17:54.772883Z",
     "shell.execute_reply": "2025-10-08T03:17:54.769674Z",
     "shell.execute_reply.started": "2025-10-08T03:17:54.743577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions found: 17\n",
      "             min        max       span\n",
      "count  17.000000  17.000000  17.000000\n",
      "mean   42.212353  75.277647  33.065294\n",
      "std    23.338879  10.416101  24.353492\n",
      "min    16.870000  38.000000   0.000000\n",
      "25%    25.000000  78.290000  12.480000\n",
      "50%    31.000000  78.780000  37.200000\n",
      "75%    66.000000  79.000000  53.000000\n",
      "max    79.000000  79.000000  62.130000\n",
      "   session_key    min    max   span\n",
      "0            2  16.87  79.00  62.13\n",
      "1           12  17.94  79.00  61.06\n",
      "2           11  18.00  78.00  60.00\n",
      "3            5  20.28  78.73  58.45\n",
      "4           20  25.00  62.20  37.20\n",
      "5            1  26.00  79.00  53.00\n",
      "6           27  26.00  78.54  52.54\n",
      "7            6  27.00  79.00  52.00\n",
      "8           18  31.00  79.00  48.00\n",
      "9           26  36.00  38.00   2.00\n",
      "10          15  48.00  79.00  31.00\n",
      "11          14  64.31  78.29  13.98\n",
      "12           3  66.00  78.78  12.78\n",
      "13          21  66.21  78.69  12.48\n",
      "14          24  71.00  76.49   5.49\n",
      "15          23  79.00  79.00   0.00\n",
      "16          22  79.00  79.00   0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "print(\"Sessions found:\", df_pred[\"session_key\"].nunique())\n",
    "soc_ranges = (\n",
    "    df_pred.groupby(\"session_key\")[\"soc\"]\n",
    "    .agg([\"min\",\"max\"])\n",
    "    .sort_values(\"min\")\n",
    "    .reset_index()\n",
    ")\n",
    "soc_ranges[\"span\"] = soc_ranges[\"max\"] - soc_ranges[\"min\"]\n",
    "print(soc_ranges.describe())\n",
    "print(soc_ranges.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65343495-aaca-41b3-b0ce-05b1bbbd89a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T03:48:35.829017Z",
     "iopub.status.busy": "2025-10-08T03:48:35.828723Z",
     "iopub.status.idle": "2025-10-08T03:48:36.372356Z",
     "shell.execute_reply": "2025-10-08T03:48:36.371486Z",
     "shell.execute_reply.started": "2025-10-08T03:48:35.828995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: /home/sagemaker-user/RCT NEW/rct_model_project/model/xgb.json\n",
      "Using: /home/sagemaker-user/output/features/rct/rct_all.csv\n",
      "Rows loaded: 1015\n",
      "Sessions detected: 17\n",
      "Predictions: 1015\n",
      "  Adjusted SOC window to best available contiguous coverage: 20→75%. Sessions used: 3\n",
      "\n",
      "=== Fleet-average time per 5% SOC band ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soc_band</th>\n",
       "      <th>avg_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20–25%</td>\n",
       "      <td>13.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25–30%</td>\n",
       "      <td>8.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30–35%</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35–40%</td>\n",
       "      <td>6.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40–45%</td>\n",
       "      <td>6.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45–50%</td>\n",
       "      <td>5.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50–55%</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55–60%</td>\n",
       "      <td>7.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60–65%</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65–70%</td>\n",
       "      <td>9.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70–75%</td>\n",
       "      <td>21.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   soc_band  avg_minutes\n",
       "0    20–25%        13.02\n",
       "1    25–30%         8.60\n",
       "2    30–35%         6.01\n",
       "3    35–40%         6.84\n",
       "4    40–45%         6.45\n",
       "5    45–50%         5.72\n",
       "6    50–55%         5.91\n",
       "7    55–60%         7.13\n",
       "8    60–65%         5.68\n",
       "9    65–70%         9.44\n",
       "10   70–75%        21.37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated average total charging time 20→75% SOC: 96.16 minutes\n",
      " Completed using physically correct band math (RCT@lo − RCT@hi), monotone-smoothed predictions, and best-available SOC coverage.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RCT MODEL VALIDATION — ZERO-ERROR, DATA-ADAPTIVE POST-PROCESSING\n",
    "# =============================================================================\n",
    "# What this does (no retraining / no redeploy):\n",
    "# 1) Finds your sessionized dataset (rct_all.*), fixes SOC units, ensures session_key.\n",
    "# 2) Loads your XGBoost model and predicts RCT (minutes) with robust feature alignment.\n",
    "# 3) Enforces monotonic RCT↓ within each session (physically consistent).\n",
    "# 4) Computes minutes per 5% SOC band using the CORRECT math: minutes = RCT@lo − RCT@hi.\n",
    "# 5) If no session covers the ideal 20–80% window, it automatically finds the largest\n",
    "#    contiguous SOC window covered by at least one session and reports it.\n",
    "# 6) Returns fleet-average minutes per band and total time for the chosen window.\n",
    "#\n",
    "# This cell is defensive: it prints warnings instead of raising exceptions.\n",
    "# =============================================================================\n",
    "\n",
    "import os, glob, math, numpy as np, pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# ----------------------------- PATHS -----------------------------------------\n",
    "BASE_DIR  = \"/home/sagemaker-user/RCT NEW/rct_model_project\"\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"model\")\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"xgb.json\")\n",
    "\n",
    "print(\"Model:\", MODEL_PATH)\n",
    "\n",
    "# Try the usual location first, but search broadly as a fallback\n",
    "default_rct_all = \"/home/sagemaker-user/output/features/rct/rct_all.csv\"\n",
    "cands = []\n",
    "if os.path.isfile(default_rct_all):\n",
    "    cands.append(default_rct_all)\n",
    "cands += glob.glob(os.path.expanduser(\"/home/sagemaker-user/**/rct_all.*\"), recursive=True)\n",
    "# Dedup while preserving order\n",
    "seen = set(); rct_paths = []\n",
    "for p in cands:\n",
    "    if p not in seen:\n",
    "        rct_paths.append(p); seen.add(p)\n",
    "\n",
    "if not rct_paths:\n",
    "    print(\" Could not find rct_all.* under /home/sagemaker-user. \"\n",
    "          \"Please confirm the path and re-run.\")\n",
    "    rct_paths = []\n",
    "\n",
    "RAW_PATH = rct_paths[0] if rct_paths else None\n",
    "print(\"Using:\", RAW_PATH)\n",
    "\n",
    "# ----------------------------- LOAD DATA -------------------------------------\n",
    "df_raw = pd.DataFrame()\n",
    "if RAW_PATH:\n",
    "    try:\n",
    "        if RAW_PATH.lower().endswith(\".parquet\"):\n",
    "            df_raw = pd.read_parquet(RAW_PATH)\n",
    "        else:\n",
    "            df_raw = pd.read_csv(RAW_PATH)\n",
    "    except Exception as e:\n",
    "        print(\" Failed to read rct_all:\", e)\n",
    "\n",
    "if df_raw.empty:\n",
    "    # Last resort: fall back to rct_train/test.csv just so the cell runs,\n",
    "    # though results may be less realistic than sessionized rct_all.\n",
    "    fallback = os.path.join(BASE_DIR, \"rct_train\", \"test.csv\")\n",
    "    if os.path.isfile(fallback):\n",
    "        print(\"  Falling back to:\", fallback)\n",
    "        df_raw = pd.read_csv(fallback)\n",
    "    else:\n",
    "        print(\" No usable data file found. Stopping gracefully.\")\n",
    "        display(pd.DataFrame({\"status\":[\"no_data\"]}))\n",
    "        raise SystemExit\n",
    "\n",
    "print(\"Rows loaded:\", len(df_raw))\n",
    "\n",
    "# ----------------------------- SOC & SESSION KEY -----------------------------\n",
    "if \"soc\" not in df_raw.columns:\n",
    "    print(\"  'soc' column not found. Stopping.\")\n",
    "    display(pd.DataFrame({\"status\":[\"no_soc_column\"]}))\n",
    "    raise SystemExit\n",
    "\n",
    "# Ensure SOC is percent (0..100)\n",
    "try:\n",
    "    df_raw[\"soc\"] = pd.to_numeric(df_raw[\"soc\"], errors=\"coerce\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "soc_max = float(df_raw[\"soc\"].max())\n",
    "if soc_max <= 1.5:\n",
    "    df_raw[\"soc\"] = df_raw[\"soc\"] * 100.0\n",
    "    print(\" Scaled SOC from 0–1 to 0–100.\")\n",
    "\n",
    "# Build session_key if missing (conservative continuity logic)\n",
    "if \"session_key\" not in df_raw.columns:\n",
    "    if {\"session_id\",\"yyyymm\"}.issubset(df_raw.columns):\n",
    "        df_raw[\"session_key\"] = (\n",
    "            df_raw[\"yyyymm\"].astype(str) + \"-\" +\n",
    "            df_raw[\"session_id\"].astype(\"Int64\").astype(str).str.zfill(6)\n",
    "        )\n",
    "    elif \"session_id\" in df_raw.columns:\n",
    "        df_raw[\"session_key\"] = df_raw[\"session_id\"].astype(\"Int64\").astype(str)\n",
    "    else:\n",
    "        print(\"ℹ️  Synthesizing session_key by continuity (SOC/time)...\")\n",
    "        s = df_raw.copy()\n",
    "        sort_cols=[]\n",
    "        if \"vehicle\" in s.columns:          sort_cols.append(\"vehicle\")\n",
    "        if \"elapsed_min\" in s.columns:      sort_cols.append(\"elapsed_min\")\n",
    "        elif \"timestamp_local\" in s.columns:sort_cols.append(\"timestamp_local\")\n",
    "        else:                               sort_cols.append(\"soc\")\n",
    "        s = s.sort_values(sort_cols).reset_index(drop=True)\n",
    "        d_soc = s[\"soc\"].diff().fillna(0)\n",
    "        long_gap = pd.Series(False, index=s.index)\n",
    "        time_back = pd.Series(False, index=s.index)\n",
    "        if \"elapsed_min\" in s.columns:\n",
    "            t_diff = s[\"elapsed_min\"].diff().fillna(0)\n",
    "            long_gap  = t_diff > 60     # >60 min break\n",
    "            time_back = t_diff < 0      # time reversal\n",
    "        new_sess = (d_soc < -1.0) | long_gap | time_back\n",
    "        s[\"session_key\"] = new_sess.cumsum().astype(int).astype(str)\n",
    "        df_raw = s\n",
    "\n",
    "print(\"Sessions detected:\", df_raw[\"session_key\"].nunique())\n",
    "\n",
    "# ----------------------------- FEATURES & MODEL ------------------------------\n",
    "def load_feature_list(model_dir=MODEL_DIR):\n",
    "    feats_path = os.path.join(model_dir, \"feature_list.txt\")\n",
    "    feats = []\n",
    "    try:\n",
    "        with open(feats_path, \"r\") as f:\n",
    "            feats = [ln.strip() for ln in f if ln.strip()]\n",
    "    except Exception as e:\n",
    "        print(\"  Could not read feature_list.txt:\", e)\n",
    "    return feats\n",
    "\n",
    "feats = load_feature_list(MODEL_DIR)\n",
    "if not feats:\n",
    "    print(\"  Empty feature list; will attempt to use all numeric columns except obvious non-features.\")\n",
    "    non_feats = {\"rct_minutes\",\"label\",\"target\",\"session_key\",\"session_id\",\"timestamp_local\",\"elapsed_min\"}\n",
    "    feats = [c for c in df_raw.columns if c not in non_feats and str(df_raw[c].dtype)!='object']\n",
    "\n",
    "X = pd.DataFrame({c: df_raw.get(c, np.nan) for c in feats})[feats]\n",
    "\n",
    "# Keep cols needed for post-processing\n",
    "keep = [c for c in [\n",
    "    \"soc\",\"elapsed_min\",\"timestamp_local\",\"vehicle\",\n",
    "    \"session_key\",\"session_id\",\"current\",\"current_master\",\"current_slave\"\n",
    "] if c in df_raw.columns]\n",
    "df_keep = df_raw[keep].copy()\n",
    "\n",
    "# Load model\n",
    "bst = xgb.Booster()\n",
    "try:\n",
    "    bst.load_model(MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print(\"  Could not load model:\", e)\n",
    "    display(pd.DataFrame({\"status\":[\"no_model\"]}))\n",
    "    raise SystemExit\n",
    "\n",
    "# Robust DMatrix build\n",
    "def make_dmatrix_aligned(X, bst):\n",
    "    if getattr(bst, \"feature_names\", None) is not None:\n",
    "        names = list(bst.feature_names)\n",
    "        # If model has generic f0,f1,... treat as unnamed\n",
    "        if all(str(n).startswith(\"f\") and str(n)[1:].isdigit() for n in names):\n",
    "            return xgb.DMatrix(X.to_numpy(copy=True))\n",
    "        missing = [c for c in names if c not in X.columns]\n",
    "        if missing:\n",
    "            # Fall back to unnamed if the declared names don't match\n",
    "            return xgb.DMatrix(X.to_numpy(copy=True))\n",
    "        return xgb.DMatrix(X[names], feature_names=names)\n",
    "    return xgb.DMatrix(X.to_numpy(copy=True))\n",
    "\n",
    "dmat = make_dmatrix_aligned(X, bst)\n",
    "pred = bst.predict(dmat)\n",
    "df_pred = df_keep.copy()\n",
    "df_pred[\"predicted_rct\"] = pred\n",
    "print(\"Predictions:\", len(pred))\n",
    "\n",
    "# ---------------------- MONOTONICITY ENFORCEMENT (per session) ---------------\n",
    "def enforce_monotone_decreasing(y):\n",
    "    \"\"\"Make series non-increasing (isotonic via cumulative min from left).\"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    # Ensure RCT never goes below zero\n",
    "    y = np.maximum(y, 0.0)\n",
    "    # Enforce monotone non-increasing as SOC rises\n",
    "    out = y.copy()\n",
    "    for i in range(1, len(out)):\n",
    "        if out[i] > out[i-1]:\n",
    "            out[i] = out[i-1]\n",
    "    return out\n",
    "\n",
    "def smooth_series(s, win=3):\n",
    "    return s.rolling(win, center=True, min_periods=1).median()\n",
    "\n",
    "def interp_at(x, y, xq):\n",
    "    x = np.asarray(x); y = np.asarray(y)\n",
    "    return float(np.interp(xq, x, y, left=y[0], right=y[-1]))\n",
    "\n",
    "# Sort helper\n",
    "def sort_session(g):\n",
    "    if \"elapsed_min\" in g.columns:      return g.sort_values(\"elapsed_min\")\n",
    "    if \"timestamp_local\" in g.columns:  return g.sort_values(\"timestamp_local\")\n",
    "    return g.sort_values(\"soc\")\n",
    "\n",
    "# Prepare per-session, monotone-smoothed predictions\n",
    "def prepare_session(g):\n",
    "    g = sort_session(g).copy()\n",
    "    g[\"predicted_rct_smooth\"] = smooth_series(g[\"predicted_rct\"])\n",
    "    g[\"predicted_rct_smooth\"] = enforce_monotone_decreasing(g[\"predicted_rct_smooth\"].values)\n",
    "    return g\n",
    "\n",
    "# ---------------------- DETERMINE BEST SOC WINDOW ----------------------------\n",
    "# Try ideal window first\n",
    "ideal_low, ideal_high = 20, 80\n",
    "sessions = []\n",
    "for sid, grp in df_pred.groupby(\"session_key\"):\n",
    "    s = prepare_session(grp)\n",
    "    sessions.append((sid, s))\n",
    "\n",
    "def covers(s, a, b):\n",
    "    m1, m2 = float(s[\"soc\"].min()), float(s[\"soc\"].max())\n",
    "    return (m1 <= a) and (m2 >= b)\n",
    "\n",
    "have_ideal = [sid for sid, s in sessions if covers(s, ideal_low, ideal_high)]\n",
    "\n",
    "if have_ideal:\n",
    "    low, high = ideal_low, ideal_high\n",
    "    chosen_sessions = have_ideal\n",
    "    print(f\"✅ Using ideal SOC window {low}→{high}%. Sessions used:\", len(chosen_sessions))\n",
    "else:\n",
    "    # Build a coverage map in 5% bands; choose the largest contiguous block with any coverage\n",
    "    all_soc = pd.concat([s[[\"soc\"]].assign(session_key=sid) for sid, s in sessions], ignore_index=True)\n",
    "    global_min = int(math.floor(all_soc[\"soc\"].min()/5)*5)\n",
    "    global_max = int(math.ceil(all_soc[\"soc\"].max()/5)*5)\n",
    "    if global_max <= global_min + 5:\n",
    "        global_min = max(global_min-5, 0)\n",
    "        global_max = min(global_max+5, 100)\n",
    "    edges = list(range(max(0,global_min), min(100,global_max)+5, 5))\n",
    "\n",
    "    band_coverage = []\n",
    "    for i in range(len(edges)-1):\n",
    "        lo, hi = edges[i], edges[i+1]\n",
    "        covered = []\n",
    "        for sid, s in sessions:\n",
    "            if (s[\"soc\"].min() <= lo) and (s[\"soc\"].max() >= hi):\n",
    "                covered.append(sid)\n",
    "        band_coverage.append((lo,hi,covered))\n",
    "\n",
    "    # Find the longest contiguous run of bands with >=1 covering session\n",
    "    best_lo, best_hi, best_len = None, None, 0\n",
    "    cur_lo, cur_hi, cur_len = None, None, 0\n",
    "    for (lo,hi,covered) in band_coverage:\n",
    "        if covered:\n",
    "            if cur_len == 0:\n",
    "                cur_lo, cur_hi, cur_len = lo, hi, 1\n",
    "            else:\n",
    "                cur_hi, cur_len = hi, cur_len+1\n",
    "            if cur_len > best_len:\n",
    "                best_lo, best_hi, best_len = cur_lo, cur_hi, cur_len\n",
    "        else:\n",
    "            cur_lo, cur_hi, cur_len = None, None, 0\n",
    "\n",
    "    if best_len == 0:\n",
    "        # Absolute worst case: return median RCT at each session's min/max SOC span\n",
    "        print(\"  No overlapping bands across sessions. \"\n",
    "              \"Reporting per-session span medians instead of fleet total.\")\n",
    "        spans = []\n",
    "        for sid, s in sessions:\n",
    "            s = prepare_session(s)\n",
    "            lo, hi = float(s[\"soc\"].min()), float(s[\"soc\"].max())\n",
    "            # Total time for that session's actual range\n",
    "            def rct_at(p): return interp_at(s[\"soc\"], s[\"predicted_rct_smooth\"], p)\n",
    "            total = max(0.0, rct_at(lo) - rct_at(hi))\n",
    "            spans.append({\"session_key\":sid, \"soc_low\":lo, \"soc_high\":hi, \"total_minutes\":total})\n",
    "        spans = pd.DataFrame(spans)\n",
    "        display(spans.describe())\n",
    "        print(\" Completed with per-session spans (no common window).\")\n",
    "        # Stop cleanly\n",
    "        raise SystemExit\n",
    "\n",
    "    low, high = best_lo, best_hi\n",
    "    # sessions that cover the *entire chosen window*\n",
    "    chosen_sessions = [sid for sid, s in sessions if covers(s, low, high)]\n",
    "    print(f\"  Adjusted SOC window to best available contiguous coverage: {low}→{high}%. \"\n",
    "          f\"Sessions used: {len(chosen_sessions)}\")\n",
    "\n",
    "# ---------------------- BAND MINUTES + TOTAL TIME ----------------------------\n",
    "# Pick current columns just for labeling\n",
    "curr_cols = [c for c in df_pred.columns if \"current\" in c.lower()]\n",
    "i_master_col = next((c for c in curr_cols if \"slave\" not in c), (curr_cols[0] if curr_cols else None))\n",
    "i_slave_col  = next((c for c in curr_cols if \"slave\" in c), None)\n",
    "\n",
    "def bucket_label(i_abs, edges=(0,1,5,10,20,40,80,200,1000)):\n",
    "    if i_abs is None or (isinstance(i_abs,float) and math.isnan(i_abs)): return None\n",
    "    for a,b in zip(edges[:-1], edges[1:]):\n",
    "        if a <= i_abs < b: return f\"{a}–{b} A\"\n",
    "    return f\"{edges[-2]}+ A\"\n",
    "\n",
    "soc_edges = list(range(int(low), int(high)+5, 5))\n",
    "labels = [f\"{soc_edges[i]}–{soc_edges[i+1]}%\" for i in range(len(soc_edges)-1)]\n",
    "\n",
    "def summarize_session_over_window(s, low, high):\n",
    "    s = prepare_session(s)\n",
    "    def rct_at(p): return interp_at(s[\"soc\"], s[\"predicted_rct_smooth\"], p)\n",
    "    rows=[]\n",
    "    for lo, hi in zip(soc_edges[:-1], soc_edges[1:]):\n",
    "        if not ((s[\"soc\"].min() <= lo) and (s[\"soc\"].max() >= hi)): \n",
    "            continue\n",
    "        minutes = max(0.0, rct_at(lo)-rct_at(hi))\n",
    "        band = s[(s[\"soc\"]>=lo)&(s[\"soc\"]<hi)]\n",
    "        i_med_m = float(np.median(np.abs(band[i_master_col]))) if (i_master_col and not band.empty) else np.nan\n",
    "        i_med_s = float(np.median(np.abs(band[i_slave_col ]))) if (i_slave_col  and not band.empty) else np.nan\n",
    "        rows.append({\"soc_band\":f\"{lo}–{hi}%\", \"minutes_in_band\":minutes,\n",
    "                     \"median_master_A\":i_med_m, \"median_slave_A\":i_med_s,\n",
    "                     \"master_current_bucket\":bucket_label(i_med_m),\n",
    "                     \"slave_current_bucket\": bucket_label(i_med_s)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "band_tables=[]\n",
    "for sid, s in sessions:\n",
    "    if sid in chosen_sessions:\n",
    "        t = summarize_session_over_window(s, low, high)\n",
    "        if not t.empty:\n",
    "            t[\"session_key\"] = sid\n",
    "            band_tables.append(t)\n",
    "\n",
    "if not band_tables:\n",
    "    print(\"⚠️  No per-band rows after filtering; this should be rare. \"\n",
    "          \"Falling back to session span totals.\")\n",
    "    # Fallback: report per-session totals only\n",
    "    spans=[]\n",
    "    for sid, s in sessions:\n",
    "        s = prepare_session(s)\n",
    "        lo, hi = float(s[\"soc\"].min()), float(s[\"soc\"].max())\n",
    "        def rct_at(p): return interp_at(s[\"soc\"], s[\"predicted_rct_smooth\"], p)\n",
    "        total = max(0.0, rct_at(lo)-rct_at(hi))\n",
    "        spans.append({\"session_key\":sid, \"soc_low\":lo, \"soc_high\":hi, \"total_minutes\":total})\n",
    "    spans = pd.DataFrame(spans)\n",
    "    display(spans.describe())\n",
    "    print(\" Completed with per-session spans (no band coverage).\")\n",
    "    raise SystemExit\n",
    "\n",
    "result = pd.concat(band_tables, ignore_index=True)\n",
    "\n",
    "# Fleet averages per band (only for bands that exist)\n",
    "fleet = (result.groupby(\"soc_band\")[\"minutes_in_band\"]\n",
    "         .mean()\n",
    "         .reset_index()\n",
    "         .rename(columns={\"minutes_in_band\":\"avg_minutes\"}))\n",
    "\n",
    "# Total time = sum of average minutes across the chosen bands\n",
    "total_minutes = float(fleet[\"avg_minutes\"].sum())\n",
    "\n",
    "# --------------------------- OUTPUT -----------------------------------------\n",
    "print(\"\\n=== Fleet-average time per 5% SOC band ===\")\n",
    "display(fleet.assign(avg_minutes=lambda d: d[\"avg_minutes\"].round(2)))\n",
    "\n",
    "print(f\"\\nEstimated average total charging time {low}→{high}% SOC: {total_minutes:.2f} minutes\")\n",
    "print(\" Completed using physically correct band math (RCT@lo − RCT@hi), \"\n",
    "      \"monotone-smoothed predictions, and best-available SOC coverage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cccdd63-d269-4b67-85c5-a4a525f6d883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
